{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad552b3",
   "metadata": {},
   "source": [
    "# Task 2: Data Profiling, Cleaning & EDA\n",
    "**Objective:** Profile, clean, and explore the solar dataset for Benin so it’s ready for comparison and region-ranking tasks.\n",
    "\n",
    "This notebook includes:\n",
    "- Summary statistics and missing-value report\n",
    "- Outlier detection and cleaning\n",
    "- Time series analysis\n",
    "- Correlation and scatter plots\n",
    "- Wind and temperature analysis\n",
    "- Bubble charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7936b83",
   "metadata": {},
   "source": [
    "# Data Profiling, Cleaning & EDA-Sierraleone\n",
    "**Objective:** Profile, clean, and explore the solar dataset for Sierraleone so it’s ready for comparison and region-ranking tasks.\n",
    "\n",
    "This notebook includes:\n",
    "- Summary statistics and missing-value report\n",
    "- Outlier detection and cleaning\n",
    "- Time series analysis\n",
    "- Correlation and scatter plots\n",
    "- Wind and temperature analysis\n",
    "- Bubble charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76363a81",
   "metadata": {},
   "source": [
    "## Importing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad401e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c935c444",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set both plotting and display settings\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"D:\\Python\\Week_01\\data\\data\\togo-dapaong_qc.csv\")\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic info\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba43188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Display the first 5 rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ecc1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the last 10 rows\n",
    "print(\"\\nLast 10 rows:\")\n",
    "display(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 10 random sample rows\n",
    "print(\"\\nRandom sample of 10 rows:\")\n",
    "display(df.sample(10, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aa46fc",
   "metadata": {},
   "source": [
    "## Summary statistics and missing-value report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numeric columns\n",
    "print(\"\\nSummary statistics for numeric columns:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Percentage of missing values per column\n",
    "null_percent = df.isna().mean() * 100\n",
    "print(\"\\nPercentage of missing values:\")\n",
    "print((null_percent).round(2))\n",
    "\n",
    "# Filter columns with more than 5% nulls\n",
    "cols_with_nulls = null_percent[null_percent > 5].index.tolist()\n",
    "print(\"\\nColumns with >5% nulls:\", cols_with_nulls)\n",
    "\n",
    "# Exact duplicate rows\n",
    "dup_count = df.duplicated().sum()\n",
    "print(\"Duplicate rows:\", dup_count)\n",
    "\n",
    "# Cardinality (uniqueness) for categoricals\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "cardinality = {c: df[c].nunique() for c in cat_cols}\n",
    "print(\"Cardinality (categoricals):\", cardinality)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e411949",
   "metadata": {},
   "source": [
    "## Interpretation of Summary statistics and missing-value report\n",
    "\n",
    "### 1. **General Overview**\n",
    "- The dataset has 525,600 records — suggests 60 min × 24 hr × 365 days = 1 year of minute-level data.\n",
    "- No missing numerical data (count = 525,600 for all measured variables).\n",
    "- Comments column is empty (count = 0); can be dropped\n",
    "- **Solar data (GHI, DNI, DHI)**: Negative GHI/DNI/DHI values are incorrect entries or sensor noise need correction\n",
    "- **Module data (ModA, ModB)**: Consistent with irradiance\n",
    "- **Temperature (Tamb, TModA, TModB)**: Physically valid\n",
    "- **Humidity (RH)**: Reasonable; 9.9 %(min) low outlier may indicate a dry period or sensor drift.\n",
    "- **Wind (WS, WSgust, WSstdev, WD, WDstdev)**: Wind readings are consistent; no clear data errors.\n",
    "- **Pressure (BP)**: Normal atmospheric range at moderate altitude\n",
    "- **Flags(Cleaning Flag & Precipitation)**: Sparse cleaning events → panels mostly uncleaned., no issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3348ee",
   "metadata": {},
   "source": [
    "## Univariate Analysis for Numeric Columns Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for missing values, outliers, incorrect entries\n",
    "cols_radiation = ['GHI', 'DNI', 'DHI']\n",
    "cols_sensor = ['ModA', 'ModB']\n",
    "cols_wind = ['WS', 'WSgust']\n",
    "cols_misc = ['Cleaning', 'Precipitation']\n",
    "\n",
    "all_cols = cols_radiation + cols_sensor + cols_wind + cols_misc\n",
    "# Function to detect outliers using IQR\n",
    "def detect_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] < lower) | (df[column] > upper)]\n",
    "\n",
    "# Outliers summary\n",
    "print(\"\\nNumber of outliers per column:\")\n",
    "for col in all_cols:\n",
    "    outliers = detect_outliers(df, col)\n",
    "    print(f\"{col}: {len(outliers)}\")\n",
    "\n",
    "# Flag incorrect entries\n",
    "df_flags = pd.DataFrame(index=df.index)\n",
    "df_flags['Negative_Radiation'] = (df[cols_radiation] < 0).any(axis=1)\n",
    "df_flags['Negative_Wind'] = (df[cols_wind] < 0).any(axis=1)\n",
    "df_flags['Invalid_Cleaning'] = ~df['Cleaning'].isin([0, 1])\n",
    "df_flags['Negative_Precipitation'] = df['Precipitation'] < 0\n",
    "\n",
    "print(\"\\nRows with flagged incorrect entries:\")\n",
    "print(df_flags[df_flags.any(axis=1)])\n",
    "\n",
    "# Compute Z-scores and flag extreme values |Z|>3\n",
    "\n",
    "cols_zscore = cols_radiation + cols_sensor + cols_wind\n",
    "df_zscores = df[cols_zscore].apply(zscore)\n",
    "\n",
    "# Flag extreme values\n",
    "extreme_flags = (np.abs(df_zscores) > 3)\n",
    "print(\"\\nNumber of extreme Z-score values per column:\")\n",
    "print(extreme_flags.sum())\n",
    "\n",
    "# view rows with any extreme Z-score\n",
    "extreme_rows = df[extreme_flags.any(axis=1)]\n",
    "print(\"\\nRows with extreme Z-scores (|Z|>3):\")\n",
    "print(extreme_rows)\n",
    "\n",
    "# Handle missing values\n",
    "# Option 1: Drop rows with missing values in key columns\n",
    "# df_cleaned = df.dropna(subset=cols_radiation + cols_sensor + cols_wind)\n",
    "\n",
    "# Option 2: Impute missing values using median\n",
    "df_imputed = df.copy()\n",
    "for col in cols_radiation + cols_sensor + cols_wind + ['Precipitation']:\n",
    "    median_value = df_imputed[col].median()\n",
    "    #df_imputed[col].fillna(median_value, inplace=True)\n",
    "    df_imputed[col] = df_imputed[col].fillna(median_value)\n",
    "\n",
    "# Verify missing values are handled\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(df_imputed[all_cols].isna().sum())\n",
    "# visualize distributions and outliers\n",
    "# ---------------------------\n",
    "\n",
    "for col in all_cols:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Histogram on the left\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(df_imputed[col], bins=50, kde=True, color='skyblue')\n",
    "    plt.title(f'Histogram of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    # Boxplot on the right\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(y=df_imputed[col], color='lightgreen')\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    plt.ylabel(col)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11a7ad8",
   "metadata": {},
   "source": [
    "### Interpretation of Box plot and Histogram Report\n",
    "1. GHI, DNI, DHI (Radiation Columns)\n",
    "Histogram Interpretation:\n",
    "•\tUsually right-skewed because there are many low values (nighttime) and fewer high values (midday).\n",
    "•\tPeaks around solar noon if data is from daytime.\n",
    "•\tAny negative values would be physically impossible → indicate sensor error.\n",
    "Boxplot Interpretation:\n",
    "•\tMedian near the central value of daytime radiation.\n",
    "•\tOutliers: extremely high spikes could indicate sensor glitches.\n",
    "•\tValues below 0 should be flagged.\n",
    "\n",
    "2. ModA, ModB (Sensor Readings)\n",
    "Histogram Interpretation:\n",
    "•\tOften roughly normal if sensors behave consistently.\n",
    "•\tPeaks indicate common operating ranges.\n",
    "•\tBimodal or irregular shapes can signal malfunction or calibration issues.\n",
    "Boxplot Interpretation:\n",
    "•\tOutliers: unusually high or low readings may indicate sensor errors.\n",
    "•\tCheck symmetry: large deviations on one side may suggest drift.\n",
    "________________________________________\n",
    "3. WS, WSgust (Wind Speed)\n",
    "Histogram Interpretation:\n",
    "•\tUsually right-skewed: most readings are low, occasional gusts are high.\n",
    "•\tNegative values are physically impossible → must be flagged.\n",
    "Boxplot Interpretation:\n",
    "•\tOutliers represent strong gusts.\n",
    "•\tMedian and quartiles help understand typical wind conditions.\n",
    "•\tIf the box is very narrow, the sensor may not be capturing variability well.\n",
    "________________________________________\n",
    "4. Cleaning (1 or 0)\n",
    "Histogram Interpretation:\n",
    "•\tOnly two bars at 0 and 1.\n",
    "•\tShows frequency of cleaning events.\n",
    "Boxplot Interpretation:\n",
    "•\tWith only two unique values, boxplot is not very informative.\n",
    "•\tAny values other than 0 or 1 are invalid → need correction.\n",
    "________________________________________\n",
    "5. Precipitation (mm/min)\n",
    "Histogram Interpretation:\n",
    "•\tHighly right-skewed: most minutes have no rain (0), occasional high rainfall minutes create a long tail.\n",
    "•\tNegative values are impossible → indicate errors.\n",
    "Boxplot Interpretation:\n",
    "•\tOutliers correspond to intense rain events.\n",
    "•\tMedian is likely 0 or very low, reflecting mostly dry periods.\n",
    "________________________________________\n",
    "Summary of What to Look For\n",
    "1.\tFrom Histograms:\n",
    "o\tDistribution shape → normal, skewed, bimodal\n",
    "o\tPeaks → typical values\n",
    "o\tImpossible values (negative for radiation, wind, precipitation)\n",
    "2.\tFrom Boxplots:\n",
    "o\tOutliers → unusually high or low values\n",
    "o\tMedian & quartiles → typical operating range\n",
    "o\tFlags potential sensor errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cad19a",
   "metadata": {},
   "source": [
    "## Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ab2918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Define relevant columns for cleaning\n",
    "cols_radiation = ['GHI', 'DNI', 'DHI']\n",
    "cols_sensor = ['ModA', 'ModB']\n",
    "cols_wind = ['WS', 'WSgust']\n",
    "cols_misc = ['Cleaning', 'Precipitation']\n",
    "\n",
    "cols_numeric_for_impute = cols_radiation + cols_sensor + cols_wind + ['Precipitation']\n",
    "cols_for_zscore = cols_radiation + cols_sensor + cols_wind\n",
    "\n",
    "# ---------------------------\n",
    "#  Handle missing values: Impute median for key numeric columns\n",
    "# ---------------------------\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "for col in cols_numeric_for_impute:\n",
    "    median_value = df_cleaned[col].median()\n",
    "    df_cleaned[col] = df_cleaned[col].fillna(median_value)\n",
    "\n",
    "# For Cleaning, fill missing with 0 (assuming no cleaning event if missing)\n",
    "df_cleaned['Cleaning'] = df_cleaned['Cleaning'].fillna(0)\n",
    "\n",
    "# ---------------------------\n",
    "# Remove impossible values\n",
    "# ---------------------------\n",
    "# Negative values for radiation, wind, precipitation\n",
    "df_cleaned = df_cleaned[(df_cleaned[cols_radiation] >= 0).all(axis=1)]\n",
    "df_cleaned = df_cleaned[(df_cleaned[cols_wind] >= 0).all(axis=1)]\n",
    "df_cleaned = df_cleaned[df_cleaned['Precipitation'] >= 0]\n",
    "\n",
    "# Ensure Cleaning is only 0 or 1\n",
    "df_cleaned = df_cleaned[df_cleaned['Cleaning'].isin([0, 1])]\n",
    "\n",
    "# ---------------------------\n",
    "# Remove extreme outliers using Z-score (|Z|>3)\n",
    "# ---------------------------\n",
    "z_scores = df_cleaned[cols_for_zscore].apply(zscore)\n",
    "\n",
    "# Keep rows where all Z-scores are within ±3\n",
    "df_cleaned = df_cleaned[(np.abs(z_scores) <= 3).all(axis=1)]\n",
    "\n",
    "# ---------------------------\n",
    "# Export cleaned dataset (all columns included)\n",
    "# ---------------------------\n",
    "output_path = r\"D:\\Python\\Week_01\\Assignment\\solar-challenge-week0\\data\\sierralione_clean.csv\"\n",
    "df_cleaned.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset exported to: {output_path}\")\n",
    "print(f\"Original rows: {len(df)}, Cleaned rows: {len(df_cleaned)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe22922",
   "metadata": {},
   "source": [
    "## Bivariate Analysis\n",
    "### Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf07b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 1️⃣ Load the cleaned dataset\n",
    "# ---------------------------------------------\n",
    "df_clean = pd.read_csv(r\"D:\\Python\\Week_01\\Assignment\\solar-challenge-week0\\data\\sierralione_clean.csv\")\n",
    "\n",
    "# Ensure Timestamp column exists and convert to datetime\n",
    "df_clean.columns = df_clean.columns.str.strip()\n",
    "if 'Timestamp' not in df_clean.columns:\n",
    "    raise KeyError(\"Column 'Timestamp' not found in the dataset.\")\n",
    "\n",
    "df_clean['Timestamp'] = pd.to_datetime(df_clean['Timestamp'], errors='coerce')\n",
    "df_clean = df_clean.dropna(subset=['Timestamp'])\n",
    "df_clean = df_clean.sort_values('Timestamp')\n",
    "\n",
    "# Extract Date for daily bar aggregation\n",
    "df_clean['Date'] = df_clean['Timestamp'].dt.date\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 2️⃣ Define Variables for Visualization\n",
    "# ---------------------------------------------\n",
    "variables = ['GHI', 'DNI', 'DHI', 'Tamb']\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 3️⃣ Generate Line and Bar Charts Separately\n",
    "# ---------------------------------------------\n",
    "for var in variables:\n",
    "    if var not in df_clean.columns:\n",
    "        print(f\"⚠️ Skipping {var} — column not found.\")\n",
    "        continue\n",
    "\n",
    "    # ---- Line Chart ----\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(df_clean['Timestamp'], df_clean[var], color='tab:blue', linewidth=1)\n",
    "    plt.title(f'{var} vs Timestamp (Line Chart)')\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel(var)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ---- Daily Average Bar Chart ----\n",
    "    daily_avg = df_clean.groupby('Date')[var].mean().reset_index()\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.bar(daily_avg['Date'], daily_avg[var], color='skyblue')\n",
    "    plt.title(f'Daily Average {var} vs Date (Bar Chart)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(f'Average {var}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7160b1d9",
   "metadata": {},
   "source": [
    "## Time Series Interpretation \n",
    "1. GHI (Global Horizontal Irradiance)\n",
    "- GHI shows strong diurnal variation, with clear peaks on sunny days and dips during cloudy or rainy periods. \n",
    "- These variations align with normal solar behavior, indicating that data collection is generally consistent.\n",
    "________________________________________\n",
    "2. DNI (Direct Normal Irradiance)\n",
    "- The DNI time series exhibits sharp peaks on clear-sky days, confirming normal direct radiation patterns. \n",
    "- Periods with lower or fluctuating DNI indicate transient cloud cover or atmospheric scattering.\n",
    "________________________________________\n",
    "3. DHI (Diffuse Horizontal Irradiance)\n",
    "- DHI values tend to rise when DNI decreases — a typical inverse relationship. \n",
    "- This confirms expected physical behavior between diffuse and direct components of solar radiation.\n",
    "________________________________________\n",
    "4. Tamb (Ambient Temperature)\n",
    "- Tamb correlates positively with solar irradiance — higher temperatures occur during high GHI/DNI periods, confirming physical consistency. - Minor lags are expected and indicate correct temperature dynamics.\n",
    "________________________________________\n",
    "5. Interpretation of the Daily Average Bar Charts\n",
    "- The daily bar charts reveal overall solar resource variability and weather trends over time. \n",
    "- Periods with low GHI/DNI and high DHI suggest cloudy or rainy weather, while consistent high values imply clear-sky periods.\n",
    "\n",
    "\n",
    "6. Recommendations\n",
    "\n",
    "- Data Consistency: The smooth daily patterns suggest reliable sensors, but further checks for missing nighttime or constant values are advised.\n",
    "\n",
    "- Outlier Review: Extreme values or flat lines should be validated against maintenance logs.\n",
    "\n",
    "- Model Input: Cleaned GHI, DNI, and DHI data can be used to model solar PV or thermal system performance.\n",
    "\n",
    "- Temporal Aggregation: Hourly or daily means can be used for forecasting and trend analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2dfc99",
   "metadata": {},
   "source": [
    "### Pattern Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2cb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1️⃣ Load the cleaned dataset\n",
    "# -----------------------------------------\n",
    "df_clean = pd.read_csv(r\"D:\\Python\\Week_01\\Assignment\\solar-challenge-week0\\data\\sierralione_clean.csv\")\n",
    "\n",
    "# Ensure Timestamp column exists and convert to datetime\n",
    "df_clean.columns = df_clean.columns.str.strip()\n",
    "if 'Timestamp' not in df_clean.columns:\n",
    "    raise KeyError(\"Column 'Timestamp' not found in the dataset.\")\n",
    "\n",
    "df_clean['Timestamp'] = pd.to_datetime(df_clean['Timestamp'], errors='coerce')\n",
    "df_clean = df_clean.dropna(subset=['Timestamp'])\n",
    "df_clean = df_clean.sort_values('Timestamp')\n",
    "\n",
    "# Extract useful time components\n",
    "df_clean['Month'] = df_clean['Timestamp'].dt.month\n",
    "df_clean['Hour'] = df_clean['Timestamp'].dt.hour\n",
    "df_clean['Date'] = df_clean['Timestamp'].dt.date\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2️⃣ Monthly Patterns (GHI, DNI, DHI, Tamb)\n",
    "# -----------------------------------------\n",
    "monthly_avg = df_clean.groupby('Month')[['GHI', 'DNI', 'DHI', 'Tamb']].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "monthly_avg.plot(kind='bar', figsize=(12, 6), colormap='plasma')\n",
    "plt.title('Monthly Average Patterns of Solar Irradiance and Temperature')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Value')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------\n",
    "# 3️⃣ Daily (Hourly) Trends\n",
    "# -----------------------------------------\n",
    "hourly_avg = df_clean.groupby('Hour')[['GHI', 'DNI', 'DHI', 'Tamb']].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "hourly_avg.plot(figsize=(12, 6), linewidth=2, colormap='viridis')\n",
    "plt.title('Average Hourly Trends of Solar Irradiance and Temperature')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Average Value')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------\n",
    "# 4️⃣ Detect and Visualize Anomalies\n",
    "# -----------------------------------------\n",
    "for col in ['GHI', 'DNI', 'DHI', 'Tamb']:\n",
    "    if col in df_clean.columns:\n",
    "        threshold = df_clean[col].mean() + 3 * df_clean[col].std()\n",
    "        df_clean[f'{col}_anomaly'] = df_clean[col] > threshold\n",
    "        count = df_clean[f'{col}_anomaly'].sum()\n",
    "        print(f\"⚠️ {col}: {count} potential anomalies detected (values > mean + 3*std)\")\n",
    "\n",
    "# Example: Visualize anomalies for GHI\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(df_clean['Timestamp'], df_clean['GHI'], label='GHI', color='orange')\n",
    "plt.scatter(\n",
    "    df_clean.loc[df_clean['GHI_anomaly'], 'Timestamp'],\n",
    "    df_clean.loc[df_clean['GHI_anomaly'], 'GHI'],\n",
    "    color='red', label='Anomalies', s=20\n",
    ")\n",
    "plt.title('GHI Time Series with Anomalies Highlighted')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('GHI')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7520c5",
   "metadata": {},
   "source": [
    "### Time Series Interpretation- Monthly and Daily\n",
    "1. Monthly Patterns\n",
    "- The monthly variation in GHI and DNI confirms the site’s dependence on seasonal weather patterns — clear skies increase direct irradiance while cloud cover reduces it.\n",
    "- DHI’s opposite trend serves as an indirect indicator of atmospheric conditions.\n",
    "- The temperature trend correlates well with solar exposure, reflecting expected climatic variation in the Bumbuna region.\n",
    "________________________________________\n",
    "2. Daily (Diurnal) Trends\n",
    "- These diurnal patterns are physically consistent with natural solar behavior. \n",
    "- The lag between irradiance and temperature highlights the thermal inertia of the environment — the atmosphere and surfaces take time to warm and cool.\n",
    "- Any deviation from these smooth patterns (e.g., sudden spikes, missing peaks, or flattened curves) may indicate sensor errors, maintenance events, or transient weather phenomena such as storms or shading.\n",
    "________________________________________\n",
    "3. Anomalies and Unusual Observations\n",
    "- **Detected Anomalies**\n",
    "     - Spikes in GHI/DNI during early morning or late evening hours may indicate sensor misalignment or reflection.\n",
    "     - Sudden drops to zero during daylight hours may correspond to cloud passages, dust, or temporary obstructions.\n",
    "     - Temperature outliers (sharp increases or decreases) could result from sensor calibration drift, rain cooling, or abrupt environmental changes.\n",
    "     - Flat-line readings (constant values over extended periods) may suggest sensor malfunction or data logging errors.\n",
    "- **Interpretation**\n",
    "- Identifying and investigating these anomalies is crucial for ensuring the quality of solar datasets.\n",
    "- Persistent outliers should be compared against weather logs and maintenance records. Data gaps or unrealistic values can be corrected through imputation or flagged for exclusion before modeling or system design.\n",
    "\n",
    "**Conclusion**\n",
    "- The temporal analysis of the Sierra Leone Bumbuna dataset reveals strong seasonal and diurnal consistency, confirming that the sensors capture realistic solar and meteorological patterns.\n",
    "- Observed anomalies are within expected operational ranges and can be managed with standard cleaning procedures (e.g., Z-score filtering, interpolation, or outlier masking).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5ad65",
   "metadata": {},
   "source": [
    "### Showing Cleaning Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea707f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip column names to avoid whitespace issues\n",
    "df_clean.columns = df_clean.columns.str.strip()\n",
    "\n",
    "# Check required columns\n",
    "required_cols = ['Cleaning', 'ModA', 'ModB']\n",
    "for col in required_cols:\n",
    "    if col not in df_clean.columns:\n",
    "        raise KeyError(f\"Column '{col}' not found in dataset.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Group by Cleaning flag and compute averages\n",
    "# -----------------------------\n",
    "avg_mod = df_clean.groupby('Cleaning')[['ModA', 'ModB']].mean().reset_index()\n",
    "avg_mod['Cleaning'] = avg_mod['Cleaning'].map({0: 'Pre-Clean', 1: 'Post-Clean'})  # Optional: label\n",
    "\n",
    "print(\"Average ModA & ModB pre- and post-clean:\")\n",
    "print(avg_mod)\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Plot the results\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x='Cleaning', y='value', hue='variable',\n",
    "            data=pd.melt(avg_mod, id_vars='Cleaning', value_vars=['ModA', 'ModB']),\n",
    "            palette='Set2')\n",
    "\n",
    "plt.title('Average ModA & ModB Pre- and Post-Clean')\n",
    "plt.ylabel('Average Value')\n",
    "plt.xlabel('Cleaning Status')\n",
    "plt.legend(title='Module')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ee5f1",
   "metadata": {},
   "source": [
    "## Interpretation of the Cleaning Impact\n",
    "1. Observation from the bar chart and grouped averages:\n",
    "\n",
    "- Both ModA and ModB show higher average readings after cleaning (Post-Clean) compared to before (Pre-Clean).\n",
    "\n",
    "- The increase is consistent across both modules, suggesting that the cleaning process improved sensor performance or removed obstructions affecting measurements.\n",
    "\n",
    "- The difference between ModA and ModB is relatively small, indicating that both sensors respond similarly to cleaning.\n",
    "\n",
    "2. Implication:\n",
    "\n",
    "- The cleaning process effectively restored the accuracy and reliability of the module readings.\n",
    "\n",
    "- Pre-clean data may have been underreporting irradiance or module output due to dirt, dust, or other obstructions.\n",
    "\n",
    "3. Conclusion\n",
    "\n",
    "- Cleaning has a measurable positive impact on module sensor performance.\n",
    "\n",
    "- Post-cleaning readings are more representative of actual solar irradiance or module output.\n",
    "\n",
    "- This confirms that regular maintenance and cleaning are essential for reliable solar monitoring and performance evaluation.\n",
    "\n",
    "The analysis is a bivariate study examining one categorical factor (Cleaning) against numerical outcomes (ModA and ModB).\n",
    "\n",
    "4. Recommendations\n",
    "\n",
    "- Regular Cleaning Schedule\n",
    "\n",
    "    - Implement a routine cleaning protocol for all solar modules to maintain optimal sensor performance.\n",
    "\n",
    "    - Frequency should be determined based on dust levels, rainfall, and module sensitivity.\n",
    "\n",
    "- Monitor Module Performance Post-Cleaning\n",
    "\n",
    "    - Continue to track ModA and ModB outputs to confirm the effectiveness of each cleaning cycle.\n",
    "\n",
    "    - Use automated alerts for unexpected drops in readings that may indicate dirt accumulation or sensor malfunction.\n",
    "\n",
    "- Data Quality Management\n",
    "\n",
    "    - Flag pre-clean readings in historical datasets when performing analysis to account for potential underreporting.\n",
    "\n",
    "    - Consider imputation or adjustment for pre-clean values in performance modeling.\n",
    "\n",
    "- Extend Analysis to Other Modules\n",
    "\n",
    "    - If the facility has more modules, apply the same cleaning-effect analysis to all to ensure consistency across the system.\n",
    "\n",
    "- Integrate Cleaning Impact into Predictive Models\n",
    "\n",
    "    - Factor the cleaning effect into solar energy production forecasts to improve accuracy.\n",
    "\n",
    "**Strategic Takeaway**\n",
    "Maintaining module cleanliness is a simple yet impactful operational strategy that directly improves sensor accuracy and overall energy yield predictions. Regular cleaning combined with monitoring ensures data reliability, better performance analysis, and informed investment decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d3cea7",
   "metadata": {},
   "source": [
    "## Multivariant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa6bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from windrose import WindroseAxes\n",
    "\n",
    "# -----------------------------\n",
    "# 1️⃣ Load cleaned dataset\n",
    "# -----------------------------\n",
    "df_clean = pd.read_csv(r\"D:\\Python\\Week_01\\Assignment\\solar-challenge-week0\\data\\sierralione_clean.csv\")\n",
    "df_clean.columns = df_clean.columns.str.strip()  # Remove leading/trailing spaces\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Correlation Heatmap\n",
    "# -----------------------------\n",
    "corr_vars = ['GHI', 'DNI', 'DHI', 'TModA', 'TModB']\n",
    "corr_matrix = df_clean[corr_vars].corr()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title('Correlation Heatmap: GHI, DNI, DHI, TModA, TModB')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Scatter Plots\n",
    "# -----------------------------\n",
    "scatter_vars = ['WS', 'WSgust', 'WD']\n",
    "for var in scatter_vars:\n",
    "    if var in df_clean.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.scatterplot(x=df_clean[var], y=df_clean['GHI'])\n",
    "        plt.title(f'{var} vs GHI')\n",
    "        plt.xlabel(var)\n",
    "        plt.ylabel('GHI')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# ○\tHistograms for GHI and one other variable (e.g., WS).\n",
    "# RH vs Tamb and RH vs GHI\n",
    "variables = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
    "\n",
    "# -----------------------------\n",
    "# Plot side-by-side histograms\n",
    "# -----------------------------\n",
    "num_vars = len(variables)\n",
    "fig, axes = plt.subplots(nrows=(num_vars+1)//2, ncols=2, figsize=(14, 4*((num_vars+1)//2)))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, var in enumerate(variables):\n",
    "    if var not in df_clean.columns:\n",
    "        print(f\"⚠️ Skipping {var} — column not found.\")\n",
    "        continue\n",
    "\n",
    "    sns.histplot(data=df_clean, x=var, hue='Cleaning', kde=True, alpha=0.6, bins=30, ax=axes[i], palette='Set2')\n",
    "    axes[i].set_title(f'Distribution of {var} by Cleaning Status')\n",
    "    axes[i].set_xlabel(var)\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "# Remove unused subplots\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# multivariate exploratory analysis by examining how Relative Humidity (RH) influences \n",
    "# ambient temperature (Tamb) and solar irradiance (GHI).\n",
    "# Check required columns\n",
    "required_cols = ['RH', 'Tamb', 'GHI']\n",
    "for col in required_cols:\n",
    "    if col not in df_clean.columns:\n",
    "        raise KeyError(f\"Column '{col}' not found in dataset.\")\n",
    "\n",
    "# Optional: Include Cleaning as a third variable for multivariate visualization\n",
    "if 'Cleaning' in df_clean.columns:\n",
    "    df_clean['Cleaning'] = df_clean['Cleaning'].map({0: 'Pre-Clean', 1: 'Post-Clean'})\n",
    "else:\n",
    "    df_clean['Cleaning'] = 'Unknown'\n",
    "\n",
    "# -----------------------------\n",
    "# 2️⃣ Scatter Plot: RH vs Tamb with GHI as color\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(8,6))\n",
    "scatter = plt.scatter(df_clean['RH'], df_clean['Tamb'], \n",
    "                      c=df_clean['GHI'], cmap='viridis', alpha=0.6, s=30)\n",
    "plt.colorbar(scatter, label='GHI')\n",
    "plt.xlabel('Relative Humidity (RH %)')\n",
    "plt.ylabel('Ambient Temperature (Tamb °C)')\n",
    "plt.title('RH vs Tamb with GHI as Color (Multivariate)')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 3️⃣ Scatter Plot: RH vs GHI with Tamb as color\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(8,6))\n",
    "scatter = plt.scatter(df_clean['RH'], df_clean['GHI'], \n",
    "                      c=df_clean['Tamb'], cmap='plasma', alpha=0.6, s=30)\n",
    "plt.colorbar(scatter, label='Tamb')\n",
    "plt.xlabel('Relative Humidity (RH %)')\n",
    "plt.ylabel('GHI (W/m²)')\n",
    "plt.title('RH vs GHI with Tamb as Color (Multivariate)')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 4️⃣ Optional: Pairplot for RH, Tamb, GHI colored by Cleaning\n",
    "# -----------------------------\n",
    "sns.pairplot(df_clean[['RH', 'Tamb', 'GHI', 'Cleaning']], hue='Cleaning', diag_kind='kde', palette='Set2')\n",
    "plt.suptitle('Pairplot: RH, Tamb, GHI grouped by Cleaning', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 5️⃣ Correlation matrix for RH, Tamb, GHI\n",
    "# -----------------------------\n",
    "corr_matrix = df_clean[['RH', 'Tamb', 'GHI']].corr()\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title('Correlation: RH, Tamb, GHI')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# -----------------------------\n",
    "# Bubble Chart: GHI vs Tamb, bubble size = RH or BP\n",
    "# -----------------------------\n",
    "if 'RH' in df_clean.columns:\n",
    "    size_var = 'RH'\n",
    "elif 'BP' in df_clean.columns:\n",
    "    size_var = 'BP'\n",
    "else:\n",
    "    size_var = None\n",
    "\n",
    "if size_var:\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.scatter(df_clean['GHI'], df_clean['Tamb'], \n",
    "                s=df_clean[size_var]*0.5, alpha=0.5, c=df_clean[size_var], cmap='viridis')\n",
    "    plt.colorbar(label=size_var)\n",
    "    plt.xlabel('GHI')\n",
    "    plt.ylabel('Tamb')\n",
    "    plt.title(f'Bubble Chart: GHI vs Tamb, Bubble size = {size_var}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Wind Rose: WS and WD\n",
    "# -----------------------------\n",
    "if 'WS' in df_clean.columns and 'WD' in df_clean.columns:\n",
    "    plt.figure(figsize=(8,8))\n",
    "    ax = WindroseAxes.from_ax()\n",
    "    ax.bar(df_clean['WD'], df_clean['WS'], normed=True, opening=0.8, edgecolor='white')\n",
    "    ax.set_legend(title='Wind Speed (WS)')\n",
    "    plt.title('Wind Rose: WS vs WD')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba122f76",
   "metadata": {},
   "source": [
    "# Multivariate Analysis\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ Correlation Heatmap (GHI, DNI, DHI, TModA, TModB)\n",
    "\n",
    "- The heatmap shows **pairwise correlations** among solar irradiance variables (`GHI`, `DNI`, `DHI`) and module temperature readings (`TModA`, `TModB`).\n",
    "\n",
    "- **High positive correlations** (close to 1) indicate that variables move together — e.g., higher `GHI` generally corresponds to higher `DNI` and `DHI`.\n",
    "\n",
    "- Moderate correlations between `TModA`/`TModB` and irradiance variables suggest that **module temperatures rise as solar irradiance increases**, as expected.\n",
    "\n",
    "- **Interpretation:** Sensors are responding consistently to environmental conditions, and the data shows strong internal coherence.\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ Scatter Plots (WS, WSgust, WD vs GHI)\n",
    "\n",
    "- **Wind speed and gusts** (`WS`, `WSgust`) show some dispersion against `GHI`, possibly reflecting that higher wind does not directly affect instantaneous solar irradiance but may influence module cooling.\n",
    "\n",
    "- **Wind direction (`WD`) vs GHI** shows no strong trend, as expected, because irradiance primarily depends on solar position rather than wind.\n",
    "\n",
    "- **Interpretation:** No strong direct linear relationship between wind variables and GHI, but variability is worth monitoring for system performance.\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣ Histograms by Cleaning Status (GHI, DNI, DHI, ModA, ModB, WS, WSgust)\n",
    "\n",
    "- Side-by-side histograms reveal **differences in distributions between Pre-Clean and Post-Clean readings**.\n",
    "\n",
    "- **Post-Clean readings** of `ModA` and `ModB` generally shift higher, indicating **sensor cleaning improved measurement accuracy**.\n",
    "\n",
    "- Histograms of irradiance (`GHI`, `DNI`, `DHI`) and wind (`WS`, `WSgust`) show typical environmental variability, with some skewness visible.\n",
    "\n",
    "- **Interpretation:** Cleaning has a noticeable impact on module readings, while environmental variables show natural variability.\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣ Temperature Analysis: RH vs Tamb and RH vs GHI\n",
    "\n",
    "- Scatter plots with color encoding show **three-variable relationships**:\n",
    "  - `RH` vs `Tamb`, color = `GHI`\n",
    "  - `RH` vs `GHI`, color = `Tamb`\n",
    "\n",
    "- **Observations:**\n",
    "  - Higher relative humidity often corresponds to **slightly lower GHI**, reflecting cloudier or more humid conditions reducing solar irradiance.\n",
    "  - Temperature rises with GHI but can also be influenced by RH, showing multivariate interplay.\n",
    "\n",
    "- Pairplots further confirm **interdependencies among RH, Tamb, and GHI**, with differences between Pre- and Post-Clean readings visible when colored by `Cleaning`.\n",
    "\n",
    "- Correlation matrix quantifies these relationships numerically.\n",
    "\n",
    "---\n",
    "\n",
    "## 5️⃣ Bubble Chart (GHI vs Tamb, bubble size = RH or BP)\n",
    "\n",
    "- Visualizes **three variables at once**:\n",
    "  - X-axis = GHI, Y-axis = Tamb, Bubble size/color = RH or BP.\n",
    "\n",
    "- **Interpretation:**\n",
    "  - High GHI typically corresponds to higher Tamb.\n",
    "  - Bubble size/color shows that **humidity or pressure modulates temperature or perceived solar output**, highlighting multivariate relationships.\n",
    "\n",
    "---\n",
    "\n",
    "## 6️⃣ Wind Rose (WS vs WD)\n",
    "\n",
    "- Shows **distribution of wind speed across wind directions**.\n",
    "\n",
    "- **Interpretation:**\n",
    "  - Identifies prevailing wind directions and speeds at the site.\n",
    "  - Helps assess cooling effects on solar panels and potential structural considerations.\n",
    "  - Encodes **three variables simultaneously**: WS magnitude, WD direction, and frequency — true multivariate visualization.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Overall Interpretation\n",
    "\n",
    "1. **Multivariate insights:**\n",
    "   - Module temperatures (TModA, TModB) and irradiance (GHI, DNI, DHI) are strongly correlated.\n",
    "   - RH influences both temperature and solar irradiance, demonstrating environmental interactions.\n",
    "   - Sensor cleaning improves measurement quality, evident in distribution shifts.\n",
    "   - Wind patterns are mostly independent of GHI but important for system design.\n",
    "\n",
    "2. **Data quality and consistency:**\n",
    "   - Correlations and histograms suggest **cleaned data is reliable** for modeling and decision-making.\n",
    "\n",
    "3. **Environmental insights:**\n",
    "   - High RH reduces solar irradiance slightly.\n",
    "   - Wind patterns are directional and vary in intensity.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Recommendations Based on Analysis\n",
    "\n",
    "1. **Maintain regular sensor cleaning** to ensure accurate module readings.\n",
    "\n",
    "2. **Consider RH and temperature effects** in solar energy forecasting and panel efficiency models.\n",
    "\n",
    "3. **Use wind rose data** for panel cooling strategies and structural planning.\n",
    "\n",
    "4. **Leverage multivariate relationships** (RH, Tamb, GHI, ModA/ModB) for predictive maintenance and performance optimization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef93fcb8",
   "metadata": {},
   "source": [
    "## Importing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a8aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dee4ce3",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4d8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set both plotting and display settings\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"D:\\Python\\Week_01\\data\\data\\togo-dapaong_qc.csv\")\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic info\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Display the first 5 rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb52fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the last 10 rows\n",
    "print(\"\\nLast 10 rows:\")\n",
    "display(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea386366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 10 random sample rows\n",
    "print(\"\\nRandom sample of 10 rows:\")\n",
    "display(df.sample(10, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numeric columns\n",
    "print(\"\\nSummary statistics for numeric columns:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9feafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Percentage of missing values per column\n",
    "null_percent = df.isna().mean() * 100\n",
    "print(\"\\nPercentage of missing values:\")\n",
    "print((null_percent).round(2))\n",
    "\n",
    "# Filter columns with more than 5% nulls\n",
    "cols_with_nulls = null_percent[null_percent > 5].index.tolist()\n",
    "print(\"\\nColumns with >5% nulls:\", cols_with_nulls)\n",
    "\n",
    "# Exact duplicate rows\n",
    "dup_count = df.duplicated().sum()\n",
    "print(\"Duplicate rows:\", dup_count)\n",
    "\n",
    "# Cardinality (uniqueness) for categoricals\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "cardinality = {c: df[c].nunique() for c in cat_cols}\n",
    "print(\"Cardinality (categoricals):\", cardinality)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15eafee",
   "metadata": {},
   "source": [
    "## Outlier Detection and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363976b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Analysis Numeric columns only\n",
    "numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "print(df[numeric_cols].describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23172dc4",
   "metadata": {},
   "source": [
    "### Summary of Missing Values & Outliers in columns GHI, DNI, and DHI, ModA, ModB and WS, WSgust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a82517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_solar_wind_outliers(df, time_col='Timestamp'):\n",
    "    \"\"\"\n",
    "    Checks for missing values, negative/invalid values, and IQR outliers in key solar and wind columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "    \n",
    "    # Columns and physical bounds based on the statistical summary\n",
    "    columns_bounds = {\n",
    "        'GHI': (0, 1400),\n",
    "        'DNI': (0, 1000),\n",
    "        'DHI': (0, 800),\n",
    "        'ModA': (0, None),\n",
    "        'ModB': (0, None),\n",
    "        'WS': (0, 30),\n",
    "        'WSgust': (0, 50)\n",
    "    }\n",
    "    \n",
    "    summary = {}\n",
    "    \n",
    "    for col, (min_val, max_val) in columns_bounds.items():\n",
    "        # Missing values\n",
    "        missing_count = df[col].isna().sum()\n",
    "        missing_percent = df[col].isna().mean() * 100\n",
    "        \n",
    "        # Negative or above max\n",
    "        below_min = df[df[col] < min_val].shape[0] if min_val is not None else 0\n",
    "        above_max = df[df[col] > max_val].shape[0] if max_val is not None else 0\n",
    "        \n",
    "        # IQR outliers\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        iqr_outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)].shape[0]\n",
    "        \n",
    "        # Summary\n",
    "        summary[col] = {\n",
    "            'missing_count': missing_count,\n",
    "            'missing_percent': missing_percent,\n",
    "            'below_min': below_min,\n",
    "            'above_max': above_max,\n",
    "            'iqr_outliers': iqr_outliers\n",
    "        }\n",
    "    \n",
    "    return summary\n",
    "summary_report = check_solar_wind_outliers(df)\n",
    "for col, stats in summary_report.items():\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    for k, v in stats.items():\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cfb63a",
   "metadata": {},
   "source": [
    "#### plot time series with highlighted outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9863b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
    "# Spikes, negative values, or sudden jumps become visible.\n",
    "for col in columns_to_plot:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(df['Timestamp'], df[col], label=col, alpha=0.6)\n",
    "    plt.title(f\"{col} Time Series\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420092be",
   "metadata": {},
   "source": [
    "### Computing Z-scores for GHI, DNI, DHI, ModA, ModB, WS, WSgust; flag rows with |Z|>3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Columns to compute Z-scores for\n",
    "key_columns = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
    "\n",
    "# Compute Z-scores\n",
    "df_z = df[key_columns].apply(zscore)\n",
    "\n",
    "# Flag rows where |Z| > 3\n",
    "outlier_flags = (df_z.abs() > 3)\n",
    "\n",
    "# Extract rows with any outlier\n",
    "df_outliers = df[outlier_flags.any(axis=1)].copy()\n",
    "\n",
    "# Add a column listing which columns are outliers for each row\n",
    "def get_outlier_cols(row):\n",
    "    return row.index[row].tolist()\n",
    "\n",
    "df_outliers['outlier_columns'] = outlier_flags.loc[df_outliers.index].apply(get_outlier_cols, axis=1)\n",
    "\n",
    "# Summary: number of outlier rows\n",
    "print(\"Number of rows with |Z|>3 in any column:\", len(df_outliers))\n",
    "\n",
    "# Inspect first few outlier rows\n",
    "print(df_outliers.head())\n",
    "\n",
    "# Keep only the columns that have outliers in each row\n",
    "df_outlier_values = df_outliers.copy()\n",
    "for col in key_columns:\n",
    "    df_outlier_values[col] = df_outlier_values[col].where(outlier_flags[col])\n",
    "\n",
    "# Optional: only show Timestamp + columns with outliers\n",
    "df_outlier_values = df_outlier_values[['Timestamp'] + key_columns]\n",
    "\n",
    "# Display or save\n",
    "print(df_outlier_values.head(20))  # first 20 rows\n",
    "# df_outlier_values.to_csv(\"data/benin_outliers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0545aca3",
   "metadata": {},
   "source": [
    "## Cleaning the Data\n",
    "### Dropping missing values in key columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858736d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key columns\n",
    "key_columns = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
    "\n",
    "# Impute missing values with median safely\n",
    "df_imputed = df.copy()\n",
    "for col in key_columns:\n",
    "    median_val = df_imputed[col].median()\n",
    "    df_imputed[col] = df_imputed[col].fillna(median_val)  # <-- assign back instead of inplace\n",
    "\n",
    "# Check missing values\n",
    "print(\"Missing values after median imputation:\")\n",
    "print(df_imputed[key_columns].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839564c0",
   "metadata": {},
   "source": [
    "### Cleaning and Exporting cleaned DataFrame to data/benin_clean.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# Ensure the 'data' folder exists inside your workspace\n",
    "data_folder = r\"D:\\Python\\Week_01\\Assignment\\solar-challenge-week0\\data\"\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "# Key columns for cleaning\n",
    "key_columns = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
    "\n",
    "# --- Step 1: Impute missing values with median ---\n",
    "df_cleaned = df.copy()\n",
    "for col in key_columns:\n",
    "    median_val = df_cleaned[col].median()\n",
    "    df_cleaned[col] = df_cleaned[col].fillna(median_val)\n",
    "\n",
    "# --- Step 2: Compute Z-scores and flag outliers ---\n",
    "df_z = df_cleaned[key_columns].apply(zscore)\n",
    "outlier_flags = (df_z.abs() > 3)\n",
    "\n",
    "# Add a column listing which columns are outliers for each row\n",
    "def get_outlier_cols(row):\n",
    "    return row.index[row].tolist()\n",
    "\n",
    "df_cleaned['outlier_columns'] = outlier_flags.apply(get_outlier_cols, axis=1)\n",
    "\n",
    "# replace outliers with median (you can skip if you just want to flag)\n",
    "for col in key_columns:\n",
    "    median_val = df_cleaned[col].median()\n",
    "    df_cleaned.loc[outlier_flags[col], col] = median_val\n",
    "\n",
    "# --- Step 4: Summary ---\n",
    "num_outlier_rows = (outlier_flags.any(axis=1)).sum()\n",
    "print(f\"Number of rows with outliers: {num_outlier_rows}\")\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(df_cleaned[key_columns].isna().sum())\n",
    "\n",
    "# Path to save the cleaned CSV\n",
    "cleaned_csv_path = os.path.join(data_folder, \"togo_clean.csv\")\n",
    "\n",
    "# Save the cleaned DataFrame\n",
    "df_cleaned.to_csv(cleaned_csv_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved to: {cleaned_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d9408",
   "metadata": {},
   "source": [
    "### rows were affected by missing values vs. outliers vs. cleaned values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bdd0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Key columns to check\n",
    "key_columns = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
    "\n",
    "# Total rows\n",
    "total_rows = len(df)\n",
    "\n",
    "# --- Missing values ---\n",
    "missing_count_per_column = df[key_columns].isna().sum()\n",
    "rows_with_missing = df[key_columns].isna().any(axis=1).sum()\n",
    "\n",
    "# --- Z-score outliers ---\n",
    "df_z = df[key_columns].apply(zscore)\n",
    "outlier_flags = df_z.abs() > 3\n",
    "rows_with_outliers = outlier_flags.any(axis=1).sum()\n",
    "\n",
    "# --- After cleaning (median imputation and optional outlier replacement) ---\n",
    "df_cleaned = df.copy()\n",
    "for col in key_columns:\n",
    "    median_val = df_cleaned[col].median()\n",
    "    df_cleaned[col] = df_cleaned[col].fillna(median_val)\n",
    "    df_cleaned.loc[outlier_flags[col], col] = median_val\n",
    "\n",
    "rows_cleaned = (df_cleaned[key_columns] != df[key_columns]).any(axis=1).sum()\n",
    "\n",
    "# --- Summary report ---\n",
    "report = pd.DataFrame({\n",
    "    \"Total Rows\": [total_rows],\n",
    "    \"Rows with Missing Values\": [rows_with_missing],\n",
    "    \"Rows with Outliers\": [rows_with_outliers],\n",
    "    \"Rows Cleaned (Imputed or Replaced)\": [rows_cleaned]\n",
    "})\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cdf212",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4976c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load cleaned dataset\n",
    "df = pd.read_csv(r\"D:\\Python\\Week_01\\Assignment\\solar-challenge-week0\\data\\benin_clean.csv\")\n",
    "\n",
    "# Convert Timestamp to datetime\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "# Set Timestamp as index for better plotting\n",
    "df.set_index('Timestamp', inplace=True)\n",
    "\n",
    "# Columns to plot\n",
    "columns_to_plot = ['GHI', 'DNI', 'DHI', 'Tamb']\n",
    "\n",
    "# --- Line chart ---\n",
    "plt.figure(figsize=(15, 6))\n",
    "for col in columns_to_plot:\n",
    "    plt.plot(df.index, df[col], label=col)\n",
    "\n",
    "plt.title(\"Solar and Temperature Data Over Time\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ensure datetime index\n",
    "# df = df.set_index('Timestamp')\n",
    "\n",
    "# Select only numeric columns\n",
    "df_numeric = df.select_dtypes(include='number')\n",
    "\n",
    "# Hourly averages\n",
    "df_hourly = df_numeric.resample('h').mean()\n",
    "\n",
    "# Plot selected variables\n",
    "cols_to_plot = ['GHI', 'DNI', 'DHI', 'Tamb']\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "for col in cols_to_plot:\n",
    "    plt.plot(df_hourly.index, df_hourly[col], label=col)\n",
    "\n",
    "plt.title(\"Hourly Average Solar and Temperature Data\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffd18e3",
   "metadata": {},
   "source": [
    "### Observe patterns by month, trends throughout the day, or anomalies, such as peaks in solar irradiance or temperature fluctuations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec67e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by month and compute mean\n",
    "monthly_mean = df_numeric.resample('m').mean()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "for col in ['GHI', 'DNI', 'DHI', 'Tamb']:\n",
    "    plt.plot(monthly_mean.index.month, monthly_mean[col], label=col)\n",
    "\n",
    "plt.title(\"Monthly Average Trends of Solar and Temperature Data\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Mean Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "df['hour'] = df.index.hour\n",
    "hourly_pattern = df.groupby('hour')[['GHI', 'DNI', 'DHI', 'Tamb']].mean()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "for col in ['GHI', 'DNI', 'DHI', 'Tamb']:\n",
    "    plt.plot(hourly_pattern.index, hourly_pattern[col], label=col)\n",
    "\n",
    "plt.title(\"Average Diurnal Pattern (Hourly Averages Across All Days)\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Mean Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# detecting anomalies or peaks\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(df_hourly.index, df_hourly['GHI'], label='GHI', alpha=0.8)\n",
    "plt.scatter(df_hourly.index[df_hourly['GHI'] > df_hourly['GHI'].quantile(0.99)], \n",
    "            df_hourly['GHI'][df_hourly['GHI'] > df_hourly['GHI'].quantile(0.99)],\n",
    "            color='red', label='Potential Peaks', s=10)\n",
    "plt.title(\"GHI with Potential Anomalies (Top 1%)\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"GHI\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5599389",
   "metadata": {},
   "source": [
    "### Code to Group by Cleaning Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f24da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure Cleaning is numeric\n",
    "df['Cleaning'] = df['Cleaning'].astype(int)\n",
    "\n",
    "# Group by Cleaning flag\n",
    "mod_means = df.groupby('Cleaning')[['ModA', 'ModB']].mean()\n",
    "\n",
    "# Plot comparison\n",
    "mod_means.plot(kind='bar', figsize=(8,5), rot=0, color=['#4c72b0', '#55a868'])\n",
    "plt.title(\"Average Module Output Before and After Cleaning\")\n",
    "plt.xlabel(\"Cleaning Flag (0 = Before, 1 = After)\")\n",
    "plt.ylabel(\"Average Module Output (W/m²)\")\n",
    "plt.legend([\"ModA\", \"ModB\"])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: print numerical difference\n",
    "print(\"Average ModA/ModB output before vs after cleaning:\\n\")\n",
    "print(mod_means)\n",
    "print(\"\\nChange after cleaning (%):\")\n",
    "print((mod_means.loc[1] - mod_means.loc[0]) / mod_means.loc[0] * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205000ae",
   "metadata": {},
   "source": [
    "### Correlation & Relationship Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6acddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select relevant columns\n",
    "corr_cols = ['GHI', 'DNI', 'DHI', 'TModA', 'TModB']\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df[corr_cols].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap — Irradiance and Module Temperatures\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Define scatter plots\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# (a) WS vs GHI\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.scatter(df['WS'], df['GHI'], alpha=0.4)\n",
    "plt.title(\"WS vs GHI\")\n",
    "plt.xlabel(\"Wind Speed (m/s)\")\n",
    "plt.ylabel(\"GHI (W/m²)\")\n",
    "\n",
    "# (b) WSgust vs GHI\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.scatter(df['WSgust'], df['GHI'], alpha=0.4, color='orange')\n",
    "plt.title(\"WSgust vs GHI\")\n",
    "plt.xlabel(\"Wind Gust (m/s)\")\n",
    "plt.ylabel(\"GHI (W/m²)\")\n",
    "\n",
    "# (c) WD vs GHI\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.scatter(df['WD'], df['GHI'], alpha=0.4, color='green')\n",
    "plt.title(\"WD vs GHI\")\n",
    "plt.xlabel(\"Wind Direction (°)\")\n",
    "plt.ylabel(\"GHI (W/m²)\")\n",
    "\n",
    "# (d) RH vs Tamb\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.scatter(df['RH'], df['Tamb'], alpha=0.4, color='red')\n",
    "plt.title(\"RH vs Tamb\")\n",
    "plt.xlabel(\"Relative Humidity (%)\")\n",
    "plt.ylabel(\"Ambient Temperature (°C)\")\n",
    "\n",
    "# (e) RH vs GHI\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.scatter(df['RH'], df['GHI'], alpha=0.4, color='purple')\n",
    "plt.title(\"RH vs GHI\")\n",
    "plt.xlabel(\"Relative Humidity (%)\")\n",
    "plt.ylabel(\"GHI (W/m²)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c95817",
   "metadata": {},
   "source": [
    "### visualizing wind behavior and value distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fdf7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from windrose import WindroseAxes\n",
    "\n",
    "# Remove invalid data\n",
    "df_valid = df.dropna(subset=['WS', 'WD'])\n",
    "\n",
    "# Create wind rose\n",
    "ax = WindroseAxes.from_ax()\n",
    "ax.bar(df_valid['WD'], df_valid['WS'], normed=True, opening=0.8, edgecolor='white')\n",
    "ax.set_legend(title=\"Wind speed (m/s)\", bbox_to_anchor=(1.1, 0))\n",
    "plt.title(\"Wind Rose: Wind Speed vs Direction\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# GHI Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['GHI'].dropna(), bins=40, kde=True, color='gold')\n",
    "plt.title(\"Distribution of Global Horizontal Irradiance (GHI)\")\n",
    "plt.xlabel(\"GHI (W/m²)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# WS Histogram\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['WS'].dropna(), bins=40, kde=True, color='skyblue')\n",
    "plt.title(\"Distribution of Wind Speed (WS)\")\n",
    "plt.xlabel(\"Wind Speed (m/s)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dba0e4e",
   "metadata": {},
   "source": [
    "### Scatter Plots — RH vs Tamb, RH vs GHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc7a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# RH vs Temperature\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(x='RH', y='Tamb', data=df, alpha=0.3, color='coral')\n",
    "sns.regplot(x='RH', y='Tamb', data=df, scatter=False, color='black', line_kws={'lw': 2})\n",
    "plt.title(\"RH vs Ambient Temperature (Tamb)\")\n",
    "plt.xlabel(\"Relative Humidity (%)\")\n",
    "plt.ylabel(\"Temperature (°C)\")\n",
    "\n",
    "# RH vs GHI\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(x='RH', y='GHI', data=df, alpha=0.3, color='skyblue')\n",
    "sns.regplot(x='RH', y='GHI', data=df, scatter=False, color='black', line_kws={'lw': 2})\n",
    "plt.title(\"RH vs Global Horizontal Irradiance (GHI)\")\n",
    "plt.xlabel(\"Relative Humidity (%)\")\n",
    "plt.ylabel(\"GHI (W/m²)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a779738f",
   "metadata": {},
   "source": [
    "### GHI vs. Tamb with bubble size = RH or BP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dac8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Scatter with bubble size = RH\n",
    "plt.scatter(\n",
    "    df['Tamb'], df['GHI'],\n",
    "    s=df['RH'] * 2,          # scale bubble size\n",
    "    c=df['RH'],              # color by RH\n",
    "    cmap='coolwarm', alpha=0.6, edgecolors='k'\n",
    ")\n",
    "\n",
    "plt.title('GHI vs. Tamb with Bubble Size = RH', fontsize=14)\n",
    "plt.xlabel('Ambient Temperature (°C)')\n",
    "plt.ylabel('Global Horizontal Irradiance (GHI, W/m²)')\n",
    "plt.colorbar(label='Relative Humidity (%)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.scatter(\n",
    "    df['Tamb'], df['GHI'],\n",
    "    s=(df['BP'] - df['BP'].min()) / 2,  # normalize pressure to control bubble size\n",
    "    c=df['BP'], cmap='viridis', alpha=0.6, edgecolors='k'\n",
    ")\n",
    "\n",
    "plt.title('GHI vs. Tamb with Bubble Size = BP', fontsize=14)\n",
    "plt.xlabel('Ambient Temperature (°C)')\n",
    "plt.ylabel('Global Horizontal Irradiance (GHI, W/m²)')\n",
    "plt.colorbar(label='Barometric Pressure (hPa)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14,6))\n",
    "\n",
    "# RH\n",
    "axes[0].scatter(df['Tamb'], df['GHI'], s=df['RH']*2, c=df['RH'], cmap='coolwarm', alpha=0.6, edgecolors='k')\n",
    "axes[0].set_title('Bubble Size = RH')\n",
    "axes[0].set_xlabel('Tamb (°C)')\n",
    "axes[0].set_ylabel('GHI (W/m²)')\n",
    "\n",
    "# BP\n",
    "axes[1].scatter(df['Tamb'], df['GHI'], s=(df['BP'] - df['BP'].min())/2, c=df['BP'], cmap='viridis', alpha=0.6, edgecolors='k')\n",
    "axes[1].set_title('Bubble Size = BP')\n",
    "axes[1].set_xlabel('Tamb (°C)')\n",
    "axes[1].set_ylabel('GHI (W/m²)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
